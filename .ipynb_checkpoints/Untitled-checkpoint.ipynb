{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d795001b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring pip: markers 'python_version < \"3\"' don't match your environment\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/avx2, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: autoreload in /home/utsav19/env_gurobi/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: watchdog in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from autoreload) (2.1.2+computecanada)\n",
      "Requirement already satisfied: click in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from autoreload) (8.1.3+computecanada)\n",
      "Requirement already satisfied: selenium in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from autoreload) (4.8.2)\n",
      "Requirement already satisfied: trio~=0.17 in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from selenium->autoreload) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from selenium->autoreload) (1.26.9+computecanada)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from selenium->autoreload) (2021.10.8+computecanada)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from selenium->autoreload) (0.10.2)\n",
      "Requirement already satisfied: async-generator>=1.9 in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.8/site-packages (from trio~=0.17->selenium->autoreload) (1.10+computecanada)\n",
      "Requirement already satisfied: sortedcontainers in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from trio~=0.17->selenium->autoreload) (2.4.0+computecanada)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from trio~=0.17->selenium->autoreload) (21.4.0+computecanada)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9; python_version < \"3.11\" in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from trio~=0.17->selenium->autoreload) (1.1.1)\n",
      "Requirement already satisfied: outcome in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from trio~=0.17->selenium->autoreload) (1.2.0)\n",
      "Requirement already satisfied: idna in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from trio~=0.17->selenium->autoreload) (3.3+computecanada)\n",
      "Requirement already satisfied: sniffio in /cvmfs/soft.computecanada.ca/easybuild/software/2020/avx2/Core/scipy-stack/2023a/lib/python3.8/site-packages (from trio~=0.17->selenium->autoreload) (1.3.0+computecanada)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6; extra == \"socks\" in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from urllib3[socks]~=1.26->selenium->autoreload) (1.7.1+computecanada)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from trio-websocket~=0.9->selenium->autoreload) (1.2.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/utsav19/env_gurobi/lib/python3.8/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->autoreload) (0.14.0+computecanada)\n"
     ]
    }
   ],
   "source": [
    "!pip install autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2929e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as Dist\n",
    "torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "# %autoreload 2\n",
    "# %load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a377019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from functions_outsamrisk import *\n",
    "# write comments to the code below\n",
    "# #\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as Dist\n",
    "torch.set_default_tensor_type(\"torch.DoubleTensor\")\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import math\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing as mp\n",
    "def median_argmin(x):\n",
    "    \"\"\"\n",
    "    Returns the median and the index of the median of a vector\n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    idx = np.argsort(x)\n",
    "    x = x[idx]\n",
    "    med = np.median(x)\n",
    "    if len(x) % 2 == 0:\n",
    "        idx_med = idx[len(x) // 2]\n",
    "    else:\n",
    "        idx_med = idx[(len(x) + 1) // 2]\n",
    "    return med, idx_med\n",
    "\n",
    "def log_entropic_risk(y, z, b, h, c, alpha, prob): \n",
    "    loss = b*torch.maximum(y-z,torch.zeros_like(y)) + h*(torch.maximum(z-y,torch.zeros_like(y)))+c*z\n",
    "    if alpha>0:\n",
    "      return torch.exp(prob).T @ torch.exp(alpha*loss)# log(p'*exp(alpha*loss))\n",
    "    else:\n",
    "      return torch.exp(prob).T @ loss #p'*loss\n",
    "\n",
    "def entropic_risk(y, z, b, h, c, alpha, prob): \n",
    "    loss = b*torch.maximum(y-z,torch.zeros_like(y)) + h*(torch.maximum(z-y,torch.zeros_like(y)))+c*z\n",
    "    if alpha>0:\n",
    "      return (torch.exp(prob).T @ torch.exp(alpha*loss))\n",
    "    else:\n",
    "      return (torch.exp(prob).T @ loss)\n",
    "\n",
    "def cvx_erm(b, h, c,  alpha, prob, y, reg, opt=False):\n",
    "  if opt:\n",
    "    p=prob\n",
    "  else:\n",
    "    p = torch.ones(len(y))/len(y)   \n",
    "  zb = cp.Variable((len(y), ))\n",
    "  zh = cp.Variable((len(y), ))\n",
    "  z = cp.Variable()\n",
    "  t=cp.Variable()\n",
    "  constraints = [z >= 0]\n",
    "  constraints += [zh>=0, zb>=0]\n",
    "  constraints += [zh>= z - y,  zb>=y-z]\n",
    "  constraints+=[t>=p.T @ cp.exp(alpha*(b*zb+h*zh+c*z))]\n",
    "  objective = cp.Minimize(t +reg*(cp.norm(z,2)**2))\n",
    "\n",
    "  problem = cp.Problem(objective, constraints)\n",
    "  assert problem.is_dpp()\n",
    "  problem.solve(verbose=False)\n",
    "  return torch.tensor(problem.value), torch.tensor(z.value)\n",
    "\n",
    "def wass_infty(b, h, c,  alpha, prob, y, eps_wass):\n",
    "  N=len(y)\n",
    "  y_min=torch.maximum(y-eps_wass,torch.zeros_like(y))\n",
    "  y_plus= y+eps_wass\n",
    "  p = torch.ones(N)/N  \n",
    "  zb_min = cp.Variable((N, ))\n",
    "  zh_min = cp.Variable((N, ))\n",
    "  zb_plus = cp.Variable((N, ))\n",
    "  zh_plus = cp.Variable((N, ))\n",
    "  z = cp.Variable()\n",
    "  s=cp.Variable((N,))\n",
    "  constraints = [z >= 0]\n",
    "  constraints += [zh_plus>=0, zb_plus>=0]\n",
    "  constraints += [zh_min>=0, zb_min>=0]\n",
    "  constraints += [zh_min>= z - y_min,  zb_min>=y_min-z]\n",
    "  constraints += [zh_plus>= z - y_plus,  zb_plus>=y_plus-z]\n",
    "  constraints+=[s>=(1/N)*cp.exp(alpha*(b*zb_min+h*zh_min+c*z))]\n",
    "  constraints+=[s>=(1/N)*cp.exp(alpha*(b*zb_plus+h*zh_plus+c*z))]\n",
    "  objective = cp.Minimize(cp.sum(s))\n",
    "\n",
    "  problem = cp.Problem(objective, constraints)\n",
    "  assert problem.is_dpp()\n",
    "  problem.solve(solver='MOSEK',verbose=False)#, abstol=1e-4, feastol=1e-6)\n",
    "  return torch.tensor(problem.value), torch.tensor(z.value)\n",
    "\n",
    "\n",
    "def robust_wass_infty(b, h, c,  alpha, prob, y, eps_wass, num_part):\n",
    "    N=len(y)\n",
    "    le = int(len(y)/num_part)\n",
    "    p= np.ones((le,))/le\n",
    "    M=50*num_part\n",
    "    phi = cp.Variable(num_part, integer=True)\n",
    "    p = torch.ones(N)/N  \n",
    "    zb_min = cp.Variable((num_part,le))\n",
    "    zh_min = cp.Variable((num_part,le))\n",
    "    zb_plus = cp.Variable((num_part,le))\n",
    "    zh_plus = cp.Variable((num_part,le))\n",
    "    t=cp.Variable()\n",
    "    z = cp.Variable()\n",
    "    s=cp.Variable((num_part,le))\n",
    "    constraints = [z >= 0]\n",
    "    constraints += [zh_plus>=0, zb_plus>=0]\n",
    "    constraints += [zh_min>=0, zb_min>=0]\n",
    "    for i in  range(num_part):\n",
    "        ym=y[i*le:(i+1)*le]\n",
    "        y_min=torch.maximum(ym-eps_wass,torch.zeros_like(ym))\n",
    "       \n",
    "        y_plus= ym+eps_wass\n",
    "        constraints += [zh_min[i,:] >= z - y_min,  zb_min[i,:] >= y_min-z]\n",
    "        constraints += [zh_plus[i,:] >= z - y_plus,  zb_plus[i,:] >= y_plus-z]\n",
    "        constraints += [s[i,:]>=(1/N)*cp.exp(alpha*(b*zb_min[i,:]+h*zh_min[i,:]+c*z))]\n",
    "        constraints+=[s[i,:]>=(1/N)*cp.exp(alpha*(b*zb_plus[i,:]+h*zh_plus[i,:]+c*z))]\n",
    "        constraints += [t+M*phi[i]>=cp.sum(s[i,:])]\n",
    "    constraints += [phi>=0, phi<=1, cp.sum(phi)==math.ceil(num_part/2)-1]\n",
    "    objective = cp.Minimize(t)\n",
    "    \n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    assert problem.is_dpp()\n",
    "    problem.solve(solver='MOSEK',verbose=False)#, abstol=1e-4, feastol=1e-6)\n",
    "    return torch.tensor(problem.value), torch.tensor(z.value)\n",
    "\n",
    "def cvx_robust_RU_micq(b, h, c,  alpha,  y, Gamma,num_part):\n",
    "    le = int(len(y)/num_part)\n",
    "    p= np.ones((le,))/le\n",
    "    M=50*num_part\n",
    "    phi = cp.Variable(num_part, integer=True)\n",
    "    b=b.numpy()\n",
    "    h=h.numpy()\n",
    "    c=c.numpy()\n",
    "    alpha = alpha.numpy()\n",
    "    zb = cp.Variable((num_part,le))\n",
    "    zh = cp.Variable((num_part,le))\n",
    "    z = cp.Variable()\n",
    "    t = cp.Variable()\n",
    "    a = cp.Variable()\n",
    "    za = cp.Variable((num_part,le))\n",
    "    constraints = [z>=0, zb>=0, zh>=0]\n",
    "    for i in  range(num_part):\n",
    "        constraints += [t+M*phi[i]>=p.T @ ((1/Gamma)*cp.exp(alpha*(b*zb[i,:] + h*zh[i,:]+c*z))+(1-1/Gamma)*a)+\\\n",
    "            cp.sum(za[i,:])]\n",
    "        constraints+=[za>=0, za[i,:]>=(Gamma-(1/Gamma))*(cp.multiply(p, cp.exp(alpha*(b*zb[i,:] + h*zh[i,:]+c*z)))-a)]\n",
    "        constraints += [zb[i,:]>=y[i*le:(i+1)*le]-z]\n",
    "        constraints += [zh[i,:]>=z-y[i*le:(i+1)*le] ]\n",
    "    constraints += [phi>=0, phi<=1, cp.sum(phi)==math.ceil(num_part/2)-1]\n",
    "    objective = cp.Minimize(t)\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    # assert problem.is_dpp()\n",
    "    problem.solve(verbose=False)\n",
    "    return torch.tensor(problem.value),torch.tensor(z.value)\n",
    "\n",
    "\n",
    "def cvx_robust_erm_micq(b, h, c,  alpha,  y,num_part):\n",
    "    le = int(len(y)/num_part)\n",
    "    M=50*num_part\n",
    "    phi = cp.Variable(num_part, integer=True)\n",
    "    b=b.numpy()\n",
    "    h=h.numpy()\n",
    "    c=c.numpy()\n",
    "    alpha = alpha.numpy()\n",
    "    w = cp.Variable((num_part,le))\n",
    "    zb = cp.Variable((num_part,le))\n",
    "    zh = cp.Variable((num_part,le))\n",
    "    z = cp.Variable()\n",
    "    t = cp.Variable()\n",
    "    constraints = [z>=0, zb>=0, zh>=0]\n",
    "    for i in  range(num_part):\n",
    "        constraints += [t+M*phi[i]>=cp.sum(w[i,:])/le]\n",
    "        constraints += [zb[i,:]>=y[i*le:(i+1)*le]-z]\n",
    "        constraints += [zh[i,:]>=z-y[i*le:(i+1)*le] ]\n",
    "        constraints += [w[i,:]>= cp.exp(alpha*(c*z+b*zb[i,:]+h*zh[i,:])) ]\n",
    "    constraints += [phi>=0, phi<=1, cp.sum(phi)==math.ceil(num_part/2)-1]\n",
    "    objective = cp.Minimize(t)\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    # assert problem.is_dpp()\n",
    "    problem.solve(verbose=False)\n",
    "    return torch.tensor(problem.value),torch.tensor(z.value)\n",
    "\n",
    "def cvx_robust_erm(b, h, c,  alpha,  y, num_part):\n",
    "  zs = np.linspace(0,3,50)\n",
    "  a = np.zeros(len(zs),)\n",
    "  for kk, z1 in enumerate(zs):\n",
    "    z=z1\n",
    "    le = int(len(y)/num_part)\n",
    "    v =  cp.Variable((num_part,le))\n",
    "    t = cp.Variable()\n",
    "    phi = cp.Variable(num_part, integer=True)\n",
    "    constraints= [phi>=0, phi<=1, cp.sum(phi)==int(num_part/2)+1]\n",
    "    w=np.zeros((num_part,le))\n",
    "    for i in range(num_part):\n",
    "      w[i,:]=np.maximum(alpha*(c*z+b*y[i*le:(i+1)*le] -b*z),\\\n",
    "      alpha*(c*z-h*y[i*le:(i+1)*le] +h*z))\n",
    "      constraints += [t>=cp.sum(v[i,:])/le]\n",
    "      for j in range(le):\n",
    "        constraints+= [phi[i]*np.exp(w[i,j])<= v[i,j]]\n",
    "    objective = cp.Minimize(t)\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    # assert problem.is_dpp()\n",
    "    problem.solve(solver='MOSEK',verbose=False)\n",
    "    a[kk]=problem.value\n",
    "  z_opt = zs[np.argmin(a)]\n",
    "  return torch.tensor(problem.value), torch.tensor(z_opt)\n",
    "def cvx_erm_cvarlb(b, h, c,  alpha, prob, y, Gamma, RU=1):\n",
    "    p = torch.exp(prob)\n",
    "    zb = cp.Variable((len(y), ))\n",
    "    zh = cp.Variable((len(y), ))\n",
    "    za = cp.Variable((len(y), ))\n",
    "    z = cp.Variable()\n",
    "    a = cp.Variable()\n",
    "    constraints = [z >= 0]\n",
    "    constraints += [zh>=0, zb>=0]\n",
    "    #CVaR with lowerbound wager\n",
    "    if RU==1:\n",
    "        if alpha>0:\n",
    "            constraints += [zh>= z - y,  zb>=y-z, za>=0, za>=(Gamma-(1/Gamma))*(cp.multiply(p, cp.exp(alpha*(b*zb + h*zh+c*z)))-a)]\n",
    "            objective = cp.Minimize(p.T @ ((1/Gamma)*cp.exp(alpha*(b*zb + h*zh+c*z))+(1-1/Gamma)*a)+\\\n",
    "            cp.sum(za))\n",
    "        else:\n",
    "            constraints += [zh>= z - y,  zb>=y-z, za>=0, za>=(Gamma-(1/Gamma))*(cp.multiply(p, (b*zb + h*zh+c*z))-a)]\n",
    "            objective = cp.Minimize(p.T @ ((1/Gamma)*(b*zb + h*zh+c*z)+(1-1/Gamma)*a)+\\\n",
    "            cp.sum(za))\n",
    "\n",
    "    #CVAR a + Gamma * sum_i p_i(exp(alpha*loss - a)_+) = a +  * sum_i (p_i*Gamma*(exp(alpha*loss - a)_+))\n",
    "    else:\n",
    "        if alpha>0:\n",
    "            constraints += [zh>= z - y,  zb>=y-z, za>=0, za>=Gamma*(cp.multiply(p, cp.exp(alpha*(b*zb + h*zh+c*z)))-a)]\n",
    "            objective = cp.Minimize(a+cp.sum(za))\n",
    "        else:\n",
    "            constraints += [zh>= z - y,  zb>=y-z, za>=0, za>=Gamma*(cp.multiply(p, (b*zb + h*zh+c*z))-a)]\n",
    "            objective = cp.Minimize(a+cp.sum(za))\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    assert problem.is_dpp()\n",
    "    problem.solve(solver ='MOSEK', verbose=False)\n",
    "    # print(\"Gamma\", Gamma)\n",
    "    return torch.tensor(problem.value), torch.tensor(z.value)\n",
    "def bisection_loss_count(b, h, c,  alpha, epsilon, prob, y, ys, reg=1, prob_mle=1., pred=False, rudin=False):\n",
    "    lb = torch.tensor(0)  \n",
    "    reg=0\n",
    "    ub = torch.tensor(100)\n",
    "    grad1=torch.tensor(1)\n",
    "    it = 5\n",
    "    if pred:\n",
    "      f = lambda z: torch.log((1-reg)*entropic_risk(y, z, b,h, c, alpha, prob)\\\n",
    "         + reg*entropic_risk(ys, z, b, h, c, alpha, prob_mle))\n",
    "    elif rudin:\n",
    "      f = lambda z: log_entropic_risk(y, z, b,h, c, alpha, prob) + reg*(torch.norm(z,2)**2)\n",
    "    else:\n",
    "      f = lambda z: log_entropic_risk(y, z, b,h, c, alpha, prob) +1e-4*(z**2)\n",
    "    while (torch.abs(grad1) > epsilon and (it<1e4 and torch.abs(ub-lb)>1e-4*epsilon)):\n",
    "      z0 = (lb+ub)/2.0\n",
    "      grad1 = (f(z0+epsilon)-f(z0))/epsilon\n",
    "      if grad1 < 0: \n",
    "        lb = z0\n",
    "      else:\n",
    "        ub = z0\n",
    "      it+=1\n",
    "    return  f(z0), z0\n",
    "\n",
    "\n",
    "def task_loss(ys, zopt,  b, h, c, alpha,  lam_true):\n",
    "    dist = Dist.Poisson(lam_true)\n",
    "    m = nn.LogSoftmax(dim=0)\n",
    "    prob = m(dist.log_prob(ys))\n",
    "    c_out = log_entropic_risk(ys, zopt, b, h, c, alpha, prob)\n",
    "    return c_out\n",
    "   \n",
    "def task_loss_emp(zopt,  b, h, c, alpha, lam_true,samp,ys):\n",
    "#     samp = Dist.Exponential(lam_true)\n",
    "    torch.manual_seed(42)\n",
    "#     ys = samp.sample(sample_shape=torch.Size([10000000]))\n",
    "#     torch.rand(int(1e7))\n",
    "    # samp.sample(sample_shape=torch.Size([int(1e6)]))\n",
    "    prob = torch.ones_like(ys)/len(ys)\n",
    "    c_out = entropic_risk(ys, zopt, b, h, c, alpha, torch.log(prob))\n",
    "   \n",
    "    return c_out\n",
    "\n",
    "def task_loss_emp_insamp(zopt, ys,  b, h, c, alpha, lam_true):\n",
    "    # samp.sample(sample_shape=torch.Size([int(1e6)]))\n",
    "    prob = torch.log(torch.ones_like(ys)/len(ys))\n",
    "    c_out = log_entropic_risk(ys, zopt, b, h, c, alpha, prob)\n",
    "    return c_out\n",
    "\n",
    "def e2e_reg_rudin(reg,  b, h, c, alpha, zs, y):\n",
    "  loss_e2e = torch.zeros(len(zs),)\n",
    "  prob = torch.log(torch.ones_like(y)/len(y))\n",
    "  for j, z in enumerate(zs):   \n",
    "    loss_e2e[j,]=torch.log(entropic_risk(y, z, b, h, c, alpha, prob)\\\n",
    "        + reg*torch.norm(z,1))\n",
    "  idx = loss_e2e.argmin()\n",
    "  return zs[idx], loss_e2e\n",
    "\n",
    "def mle(trainy, means, ys):\n",
    "    mle_loss = torch.zeros(len(means), )\n",
    "    for j, lam in enumerate(means):\n",
    "          dist= Dist.Poisson(lam)\n",
    "    logprob = dist.log_prob(trainy) - torch.logsumexp(dist.log_prob(ys),dim=0) # sum_{i} log(Poi(y)/[sum_{i<=UB} Poi(ys_i)]\n",
    "    # logprob = dist.log_prob(trainy)\n",
    "    mle_loss[j,] = -logprob.mean() \n",
    "    # f(x) = p*(1_x==0)+(1-p)*Poi(x)\n",
    "    js = mle_loss.argmin()\n",
    "    return means[js]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae93fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "global list_result\n",
    "global opt_result\n",
    "list_result =[]\n",
    "opt_result =[]\n",
    "global wass_all\n",
    "wass_all = np.zeros((10, 2))\n",
    "def log_optresult(result):\n",
    "    opt_result.append(result)\n",
    "def log_result(result):\n",
    "    \n",
    "    \n",
    "    list_result.append(result)\n",
    "def to_numpy(x):\n",
    "    return np.array([np.round(x[i].item(),2) for i in range(len(x))])\n",
    "def compute_meansx(x):\n",
    "    return [torch.mean(x[i]).item() for i in range(len(x))]\n",
    "\n",
    "def compute_means(x):\n",
    "    return [np.mean(x[i]) for i in range(len(x))]\n",
    "\n",
    "\n",
    "def models(dataP, i_glob, train_size, b, h, c, alpha, epsilon, lam_true, UB,loss_opt,z_opt,all_eps,samp,ys, val=False):\n",
    "    trainy = dataP[:train_size]\n",
    "    valy = dataP[train_size:]\n",
    "    trainy_mle = torch.cat((trainy, valy))\n",
    "    prob = torch.log(torch.ones_like(trainy_mle)/len(trainy_mle))\n",
    "    l_erm, z_erm = bisection_loss_count(b, h, c,  alpha, epsilon, prob, trainy_mle, trainy_mle, 0) \n",
    "    # l_erm, z_erm = cvx_erm(b, h, c,  alpha, prob, trainy_mle,0)\n",
    "    # loss_erm_val = task_loss_emp( z_erm, b, h, c, alpha, lam_true)\n",
    "    Gamma=1.5\n",
    "    lw, zw = cvx_erm_cvarlb(b, h, c,  alpha, prob, trainy_mle, Gamma)\n",
    "    loss_RU_insamp = task_loss_emp( zw, b, h, c, alpha, lam_true,samp,ys)\n",
    "    ro_mean, z_robust_mean = cvx_robust_erm_micq(b, h, c,  alpha, trainy, int(1))\n",
    "    val_ro_mean = task_loss_emp(z_robust_mean, b, h, c, alpha,  lam_true,samp,ys)\n",
    "    N_parts = np.linspace(1 , 10, 10, dtype=int)\n",
    "    l_mom_in = np.zeros(len(N_parts),)\n",
    "    z_mom_all = np.zeros(len(N_parts),)\n",
    "    l_mom_out = np.zeros(len(N_parts),)\n",
    "    \n",
    "    for j, num_part in enumerate(N_parts):\n",
    "        l_mom, z_mom = cvx_robust_erm_micq(b, h, c,  alpha,  trainy_mle, num_part)\n",
    "        l_mom = task_loss_emp_insamp(z_mom, trainy_mle,  b, h, c, alpha, lam_true)\n",
    "        l_mom_in[j,] = l_mom.item()\n",
    "        z_mom_all[j,] = z_mom.item()\n",
    "        l_mom_out[j,] = task_loss_emp(z_mom.item(), b, h, c, alpha,  lam_true,samp,ys).item()\n",
    "\n",
    "    l_wass_in = np.zeros(len(all_eps),)\n",
    "    l_wass_out = np.zeros(len(all_eps),)\n",
    "    z_wass_all = np.zeros(len(all_eps),)\n",
    "    for j, eps_wass in enumerate(all_eps):\n",
    "        print(j, eps_wass) \n",
    "        l_wass, z_wass = wass_infty(b, h, c,  alpha, prob, trainy_mle, eps_wass)\n",
    "        l_wass = task_loss_emp_insamp(z_wass, trainy_mle,  b, h, c, alpha, lam_true)\n",
    "        z_wass_all[j] = z_wass.item()\n",
    "        l_wass_in[j]=l_wass.item()\n",
    "        l_wass_out[j,] =task_loss_emp(z_wass.item(), b, h, c, alpha,  lam_true,samp,ys).item()\n",
    "    l_wass_mom_in = np.zeros((len(all_eps),len(N_parts)))\n",
    "    l_wass_mom_out = np.zeros((len(all_eps),len(N_parts)))\n",
    "    z_wass_mom_all = np.zeros((len(all_eps),len(N_parts)))\n",
    "    for j, num_part in enumerate(N_parts):\n",
    "        for i, eps_wass in enumerate(all_eps):\n",
    "            l_wass_mom, z_wass_mom = robust_wass_infty(b, h, c,  alpha, prob, trainy_mle, eps_wass, num_part)\n",
    "            l_wass_mom= task_loss_emp_insamp(z_wass_mom, trainy_mle,  b, h, c, alpha, lam_true)\n",
    "            z_wass_mom_all[i,j] = z_wass_mom.item()\n",
    "            l_wass_mom_in[i,j]=l_wass_mom\n",
    "            l_wass_mom_out[i,j] =task_loss_emp(z_wass_mom.item(), b, h, c, alpha,  lam_true,samp,ys).item()\n",
    "    return i_glob,  l_erm.item(),loss_RU_insamp.item(),lw.item(),val_ro_mean.item(), ro_mean.item(), loss_opt.item(),\\\n",
    "     z_erm.item(), zw.item(), z_opt.item(), z_robust_mean.item(), l_wass_in, l_wass_out, z_wass_all, \\\n",
    "l_mom_in, l_mom_out, z_mom_all, l_wass_mom_in, l_wass_mom_out, z_wass_mom_all,\n",
    "\n",
    "# def output(b, h,c, alpha, data_all, num_ins, train_size, epsilon, lam_true, UB,loss_opt,z_opt,all_eps,samp, val):\n",
    "#     pool = mp.Pool()\n",
    "#     for i_g in range(num_ins):\n",
    "#         if i_g%20==0:\n",
    "#           print(i_g)\n",
    "#         pool.apply_async(models, args=(data_all, i_g,\\\n",
    "#          train_size, b, h, c, alpha, epsilon, lam_true, UB,loss_opt,z_opt,all_eps, samp, val), callback=log_result) \n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "def output(b, h,c, alpha, data_all, num_ins, train_size, epsilon, lam_true, UB, loss_opt,z_opt, all_eps,samp,ys, val):\n",
    "    for i_g in range(num_ins):\n",
    "        print(i_g)\n",
    "        np.random.seed(42+i_g)  # Set the seed to a fixed value for reproducibility\n",
    "        idx = np.random.randint(low=0, high=10000000, size=train_size)\n",
    "        dataP= ys[idx]\n",
    "        result = models(dataP, i_g, train_size, b, h, c, alpha, epsilon, lam_true, UB,  loss_opt,z_opt, all_eps,samp,ys,val)\n",
    "        log_result(result)\n",
    "def find_rowcolumn(array, threshold):\n",
    "    min_row_index = np.min(np.argwhere(np.max(array>threshold,1)))\n",
    "    max_col_index = np.max(np.argwhere(array[min_row_index]>threshold))\n",
    "    return min_row_index, max_col_index\n",
    "if __name__ == '__main__':\n",
    "    b, h, c = 2, 0.5, 1\n",
    "    b = torch.tensor(b)\n",
    "    h = torch.tensor(h)\n",
    "    c = torch.tensor(c)\n",
    "    alpha = torch.tensor(1.)\n",
    "    epsilon = 1e-4\n",
    "    UB = torch.tensor(5.)\n",
    "    trains= 400\n",
    "    size = trains\n",
    "    train_size = int(0.7*trains)\n",
    "    val_size = int(0.3*trains)\n",
    "    num_ins = 20\n",
    "    N_eps=5\n",
    "    threshold=0.5\n",
    "    N=int(trains/math.sqrt(trains))\n",
    "    all_eps = torch.cat([torch.tensor(0.0).unsqueeze(0),torch.logspace(0.1,1, N_eps)])\n",
    "    # int(trains/5)\n",
    "    num_parts = np.linspace(N,N,1, dtype=int)\n",
    "    #   num_parts = np.linspace(1,1,1)\n",
    "    num_gammas=6#20\n",
    "    Gammas = torch.logspace(0, 3, num_gammas)\n",
    "    val =True\n",
    "    # regs = torch.tensor([0.0])\n",
    "    regs = torch.cat([torch.tensor(0.0).unsqueeze(0),torch.linspace(0.05, 1., 10)])\n",
    "    global data_all\n",
    "    data_all=[]\n",
    "    lam_true = 3\n",
    "    torch.manual_seed(42)\n",
    "    samp = Dist.Exponential(lam_true)\n",
    "#     ys = torch.rand(10000000)\n",
    "    torch.manual_seed(42)\n",
    "    ys = samp.sample(sample_shape=torch.Size([10000000]))\n",
    "    prob = torch.ones_like(ys)/len(ys)\n",
    "    loss_opt, z_opt =    bisection_loss_count(b, h, c,  alpha, epsilon, torch.log(prob), ys,ys, 0)\n",
    "    # cvx_erm(b, h, c,  alpha, prob, ys,0, True)\n",
    "    loss_opt = task_loss_emp( z_opt, b, h, c, alpha, lam_true,samp,ys)\n",
    "    output(b, h,c, alpha, data_all, num_ins, train_size, epsilon, lam_true, UB, loss_opt,z_opt,all_eps, samp,ys,val)\n",
    "  \n",
    "    data = list_result\n",
    "    data = np.array(data[:], dtype=object)\n",
    "    with open('coverage200.csv', 'w') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(['i_g', 'erm', 'RU_val', 'RU', 'Robust_val', 'Robust_mean', 'opt', 'z_erm', 'z_RU','z_opt','z_robust',\\\n",
    "                         'l_wass_in', 'l_wass_out', 'z_wass', 'l_mom_in', 'l_mom_out', 'z_mom',\\\n",
    "                        'l_wass_mom_in', 'l_wass_mom_out', 'z_was_mom'])\n",
    "        for row in data:\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7904de03",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     x \u001b[38;5;241m=\u001b[39m mat\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.55\u001b[39m\n\u001b[1;32m     15\u001b[0m     a\u001b[38;5;241m=\u001b[39ma\u001b[38;5;241m+\u001b[39mnp\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mint\u001b[39m(x1) \u001b[38;5;28;01mfor\u001b[39;00m x1 \u001b[38;5;129;01min\u001b[39;00m x])\n\u001b[0;32m---> 16\u001b[0m idx \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(idx)\n\u001b[1;32m     18\u001b[0m data_wass_mom_in[:,:,idx]\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "data = list_result\n",
    "data = np.array(data[:], dtype=object)\n",
    "data_mom_in = np.stack(data[:,-6],axis=0)\n",
    "data_mom_out = np.stack(data[:,-5],axis=0)\n",
    "pd.DataFrame(data_mom_in>data_mom_out).mean(0)\n",
    "data_wass_in = np.stack(data[:,-9],axis=0)\n",
    "data_wass_out = np.stack(data[:,-8],axis=0)\n",
    "pd.DataFrame(data_wass_in>data_wass_out).mean(0)\n",
    "data_wass_mom_in = np.stack(data[:,-3],axis=0)\n",
    "data_wass_mom_out = np.stack(data[:,-2],axis=0)\n",
    "a =0\n",
    "for i in range(10):\n",
    "    mat = pd.DataFrame(data_wass_mom_in[:,:,i]>data_wass_mom_out[:,:,i]).mean(0).values\n",
    "    x = mat>0.55\n",
    "    a=a+np.array([int(x1) for x1 in x])\n",
    "idx = np.argwhere(a==5)[0][0]\n",
    "print(idx)\n",
    "data_wass_mom_in[:,:,idx].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba7151f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pkl', 'wb') as outfile: \n",
    "    pickle.dump(list_result, outfile, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3aa4dc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('coverage200.csv')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a333bc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "edfcf967",
   "metadata": {},
   "outputs": [],
   "source": [
    "erm = np.stack(data[:,1],axis=0)\n",
    "data_mom_in = np.stack(data[:,-6],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e91ec1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.4\n",
       "1    0.3\n",
       "2    0.4\n",
       "3    0.3\n",
       "4    0.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mom_in = np.stack(data[:,-6],axis=0)\n",
    "data_mom_out = np.stack(data[:,-5],axis=0)\n",
    "pd.DataFrame(data_mom_in>data_mom_out).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44c08b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.40\n",
       "1    0.45\n",
       "2    0.60\n",
       "3    0.60\n",
       "4    0.60\n",
       "5    0.60\n",
       "dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wass_in = np.stack(data[:,-9],axis=0)\n",
    "data_wass_out = np.stack(data[:,-8],axis=0)\n",
    "pd.DataFrame(data_wass_in>data_wass_out).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "42eb2a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wass_mom_in = np.stack(data[:,-3],axis=0)\n",
    "data_wass_mom_out = np.stack(data[:,-2],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "068ad812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 6, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wass_mom_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b9880f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "a =0\n",
    "for i in range(5):\n",
    "    mat = pd.DataFrame(data_wass_in[:,:,i]>data_wass_out[:,:,i]).mean(0).values\n",
    "    x = mat>0.55\n",
    "    a=a+np.array([int(x1) for x1 in x])\n",
    "idx = np.argwhere(a==5)[0][0]\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b6a54d3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'builtin_function_or_method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_wass_in\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'builtin_function_or_method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data_wass_in[:,:,idx].mean(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48ed40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = df.loc[:,'l_mom_out']\n",
    "data_mom_out = np.stack(data[:,-5],axis=0)\n",
    "df_mom_out = pd.DataFrame(np.stack(data[:,-5],axis=0))\n",
    "x_labels = np.linspace(1 , 20, 5, dtype=int)\n",
    "fig, ax = plt.subplots()\n",
    "df_mom_out.boxplot(ax=ax, positions=x_labels)\n",
    "_=ax.set_xticks(x_labels)\n",
    "_=ax.set_xticklabels(x_labels)\n",
    "ax.set_xlabel('partitions')\n",
    "ax.set_ylabel('Average utility (outsamp)')\n",
    "plt.axhline(y=loss_opt.item(), color='r', linestyle='--')\n",
    "# plt.axhline(y=loss_opt.item(), color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84616042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_mom_out>loss_opt.item()).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d95899",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data_mom_out).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241248fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = df.loc[:,'l_mom_in']\n",
    "data_mom_in = np.stack(data[:,-6],axis=0)\n",
    "df_mom_in = pd.DataFrame(np.stack(data[:,-6],axis=0))\n",
    "x_labels = np.linspace(1 , 20, 5, dtype=int)\n",
    "fig, ax = plt.subplots()\n",
    "df_mom_in.boxplot(ax=ax, positions=x_labels)\n",
    "_=ax.set_xticks(x_labels)\n",
    "_=ax.set_xticklabels(x_labels)\n",
    "ax.set_xlabel('partitions')\n",
    "ax.set_ylabel('Average utility(insamp)')\n",
    "plt.axhline(y=loss_opt.item(), color='r', linestyle='--')\n",
    "# plt.axhline(y=loss_opt.item(), color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696dba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = df.loc[:,'l_wass_out']\n",
    "data_wass_out = np.stack(data[:,-8],axis=0)\n",
    "df_wass_out = pd.DataFrame(np.stack(data[:,-8],axis=0))\n",
    "x_labels = np.array([np.round(i.item(),3) for i in all_eps[:-2]])\n",
    "fig, ax = plt.subplots()\n",
    "df_wass_out.iloc[:,:-2].boxplot(ax=ax)\n",
    "\n",
    "_=ax.set_xticklabels(x_labels)\n",
    "# plt.axhline(y=loss_opt.item(), color='r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fccb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = df.loc[:,'l_wass_out']\n",
    "data_wass_out = np.stack(data[:,-9],axis=0)\n",
    "df_wass_out = pd.DataFrame(np.stack(data[:,-9],axis=0))\n",
    "x_labels = np.array([np.round(i.item(),3) for i in all_eps[:-1]])\n",
    "fig, ax = plt.subplots()\n",
    "df_wass_out.iloc[:,:-1].boxplot(ax=ax)\n",
    "\n",
    "_=ax.set_xticklabels(x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fa2cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
